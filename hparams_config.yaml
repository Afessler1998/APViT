# hparams_config.yaml

# Training dynamics
batch_size: 256
epochs: 50
warmup_epochs: 5
eta_min: 0.00015
lr_factor: 512
ap_lr: 0.0002
ema_decay: 0.9

# Adaptive Patching loss
lower_quantile: 0.40
ap_loss_weight: 0.01

# Model architecture
hidden_channels: 16
attn_embed_dim: 256
num_transformer_layers: 6

# Regularization
weight_decay: 0.00015
ap_weight_decay: 0.009
stochastic_depth: 0.15
re_prob: 0.15
augment_magnitude: 5
mixup_alpha: 0.5
cutmix_alpha: 0.2
mixup_prob: 0.5
mixup_switch_prob: 0.5
label_smoothing: 0.05
